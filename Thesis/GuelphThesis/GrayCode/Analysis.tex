
\section{Analysis}
From looking at the table in the results section, it is clear that the {\sc modifiedSJT} algorithm performs 
better than the  |{\sc CyclicBar} algorithm. The reasons for this disparity in performance 
will be analyzed. Following this analysis, areas of application and practical relevance for the Listing Problem 
will be discussed along with concluding remarks.

\subsection{Performance Analysis}
    As $n \geq 9$ there is a noticeable difference between the runtimes of the two algorithms by a sizable order 
    of magnitude. Clearly the {\sc ModifiedSJT} algorithm performs better than the {\sc CyclicBar} algorithm. The reasons 
    for this improved performance are the difference in time complexities between the two algorithms.
    The time complexity for the {\sc ModifiedSJT} algorithm is constant amortized time per ladder. The time will be proven in the following lemma.
    \begin{lemma}
        The amortized time for {\sc ModifiedSJT} is $O(1)$ per ladder.
    \end{lemma}
    \begin{proof}
        Each iteration of the for loop inserts or removes a bar, thus creating a new ladder. This is done in constant time 
        per addition or removal of a bar. 
    \end{proof}
    \begin{lemma}
       The amortized time for the  {\sc CyclicBar} algorithm is $O(n^{2}) + n^{2})$ per ladder.
    \end{lemma}
    \begin{proof}
        The first $n^{2}$ term is a result of the for loop that is executed for $k=2,3, \dots n$. This for loop runs 
        from $1$ to $k$ for each value of $k$. Thus, the for loop is executed $1 + 2 + 3 + 4, ... + n-1$ times. This summation 
        is equal to $((n-1)n-2)/2$ which is reduced to $n^{2}$. There is also the second $n^{2}$ term pertaining to backtracking. 
        Once $currenLimit \geq n$, then the algorithm 
        begins to back-track. Each time $currentLimit$ increases from $n$ to $n(n-1)/2$ the number of back-tracks increases by one per 
        $currentLimit$ level.
       Thus, there are $1 + 2 + 3 + 4, ... +  ((n(n-1))/2 - n)) + 1$ back-tracks required, which is reduced to $n^{2}$. Thus, the amortized  
       time per ladder is $O(n^{2}) + n^{2})$.
    \end{proof}

    The space complexity is the same for the two algorithms. Both require a two dimensional ladder data structure whose dimensions 
    are $(2(n-1)-1)(n-1)$. Therefore the space complexity for the algorithms is $O(n^{2})$.

    \subsection{Applications}
    The applications for generating $L_{n}$ are currently unknown to me insofar as this problem has yet to be solved to my knowledge. 
    However, if I am to be granted some speculation, I could provide some hypothetical scenarios in which listing $L_{n}$ could 
    be of interest. The first hypothetical application would be to model an \emph{oblivious sorting system} for $n!$ permutations. An oblivious 
    sorting system is a system such that the sorting operations are done irrespective of the data being passed to the system~\cite{A7}. Recall 
    that a bar in a ladder simply swaps two adjacent elements in a permutation. Due to the static nature of each ladder, the swap operation 
    resulting from two elements in a permutation crossing a bar is unchanging. 
    Seeing as each ladder in $L_{n}$ sorts the corresponding permutation of order $n$, one can implement all of $L_{n}$ 
    for some arbitrary $n$ value and then pass each permutation of order $n$ through its respective ladder from $L_{n}$ 
    resulting in each permutation being sorted. The ladders from $L_{n}$ only need to be generated once and saved to disk 
    or implemented in hardware. 